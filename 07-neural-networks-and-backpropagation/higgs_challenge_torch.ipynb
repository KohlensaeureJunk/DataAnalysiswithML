{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75e5eb62-c7a4-4241-a9d7-b3ecc9780c51",
   "metadata": {},
   "source": [
    "# Example for Higgs Challenge with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e965c9-53e8-4707-9b45-7a1ecd8146a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import urllib\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b0059b-a8e9-47c9-95e9-68337a2fc8d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = Path(\"atlas-higgs-challenge-2014-v2.csv.gz\")\n",
    "url = \"http://opendata.cern.ch/record/328/files/atlas-higgs-challenge-2014-v2.csv.gz\"\n",
    "\n",
    "def prepare_data():\n",
    "    if path.exists():\n",
    "        return\n",
    "    path_prev_tutorial = Path(\"../05-overfitting-validation-metrics\") / path\n",
    "    if path_prev_tutorial.exists():\n",
    "        path.symlink_to(path_prev_tutorial)\n",
    "    if not path.exists():\n",
    "        urllib.request.urlretrieve(url, path)\n",
    "\n",
    "prepare_data()\n",
    "\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd4669a-9893-491b-b114-341e395288fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = [col for col in df.columns if col.startswith(\"DER\") or col.startswith(\"PRI\")]\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bd6a40-c43d-4a51-a913-be228f876694",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df[feature_names]\n",
    "y = df['Label']\n",
    "weight = df['Weight']\n",
    "\n",
    "(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    weight_train,\n",
    "    weight_test,\n",
    ") = train_test_split(\n",
    "    X.to_numpy(dtype=np.float32),\n",
    "    (y == \"s\").to_numpy(dtype=np.float32),\n",
    "    weight.to_numpy(dtype=np.float32),\n",
    "    test_size=0.33,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# set \"missing\" values to 0\n",
    "X_train[X_train==-999] = 0\n",
    "X_test[X_test==-999] = 0\n",
    "\n",
    "# scale\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# to balance weighted sum of signal and background\n",
    "class_weight = np.array([\n",
    "    len(y_train) / weight_train[y_train==0].sum(),\n",
    "    len(y_train) / weight_train[y_train==1].sum(),\n",
    "])\n",
    "\n",
    "# to have average weight = 1\n",
    "# use this weight in the fit\n",
    "weight_for_fit = weight_train * class_weight[y_train.astype(int)]\n",
    "weight_for_fit /= weight_for_fit.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc45251-a786-479e-9eea-b492c7a76151",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb928ec9-0f58-43ad-8185-45c9a1ff8863",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "neurons = 128\n",
    "dropout = 0.05\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(len(feature_names), neurons),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(neurons, neurons),\n",
    "    nn.BatchNorm1d(neurons),\n",
    "    nn.Dropout1d(dropout),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(neurons, neurons),\n",
    "    nn.BatchNorm1d(neurons),\n",
    "    nn.Dropout1d(dropout),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(neurons, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0736f38-bd8e-409c-be9a-265f8a0d704c",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "\n",
    "we will also split the train data again into train/val\n",
    "\n",
    "Docs:\n",
    "- [torch.utils.data](https://pytorch.org/docs/stable/data.html)\n",
    "- [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)\n",
    "- [StackDataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.StackDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a05a14-1027-4c97-952d-b877d16ee20f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0868c14f-4336-4327-bb7e-1cd3ddd2166a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StackDataset(Dataset):\n",
    "    \"\"\"\n",
    "    manual implementation of StackDataset in newer torch versions:\n",
    "    https://pytorch.org/docs/stable/data.html#torch.utils.data.StackDataset\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        self.dict = kwargs\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(next(iter(self.dict.values())))\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return {k: v[i] for k, v in self.dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1861179e-5ba3-4e07-8fd9-420d9e1f59d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "splits = train_test_split(X_train, y_train, weight_for_fit)\n",
    "dl_train = DataLoader(\n",
    "    StackDataset(X=splits[0], y=splits[2], w=splits[4]),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "dl_val = DataLoader(\n",
    "    StackDataset(X=splits[1], y=splits[3], w=splits[5]),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e45668-1ee5-4cb1-bee7-7c9460d9ac0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch = next(iter(dl_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd12b505-55fe-4206-b25a-620f50552c3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch[\"X\"].shape, batch[\"y\"].shape, batch[\"w\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97468603-5581-47c8-93de-0226ac17e2a3",
   "metadata": {},
   "source": [
    "## Optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de25675a-9268-401d-8e7d-dad1f5695cee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cd4f9b-5104-43bb-8c07-0d3abbde1577",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bccb670-3996-4e96-ba85-6ae9af460bff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678638ae-4c9b-4f9a-82f4-02d39ebe11fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef365b1b-0620-4327-9cba-2934376361da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit(dl_train, dl_val, opt, history, epochs=1, device=\"cpu\", patience=5):\n",
    "    loss_fn = F.binary_cross_entropy_with_logits\n",
    "\n",
    "    def train_step(batch):\n",
    "        model.train()\n",
    "        opt.zero_grad()\n",
    "        logits = model(batch[\"X\"]).squeeze(1)\n",
    "        loss = loss_fn(logits, batch[\"y\"], weight=batch[\"w\"])\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        return loss.cpu().detach().item()\n",
    "\n",
    "    def val_step(batch):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = model(batch[\"X\"]).squeeze(1)\n",
    "            loss = loss_fn(logits, batch[\"y\"], weight=batch[\"w\"])\n",
    "            return loss.cpu().item()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        losses = []\n",
    "        for batch in tqdm(dl_train, desc=f\"Epoch {epoch}\"):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            losses.append(train_step(batch))\n",
    "\n",
    "        val_losses = []\n",
    "        for batch in dl_val:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            val_losses.append(val_step(batch))\n",
    "    \n",
    "        history.append({\"loss\": np.mean(losses), \"val_loss\": np.mean(val_losses)})\n",
    "        print(history[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f521b43-048c-4301-9983-87512e142112",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fit(dl_train, dl_val, optimizer, history=history, epochs=5, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c648de47-f572-4206-816e-2e08d37eadc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(history).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e06716-0b2c-46ab-bb27-9e6e45f81058",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89f3319-7b93-4092-aa78-5fd0e463a39d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ams(s, b):\n",
    "    \"\"\"\n",
    "    Approximate median significance, as defined in Higgs Kaggle challenge\n",
    "\n",
    "    The number 10, added to the background yield, is a regularization term to decrease the variance of the AMS.\n",
    "    \"\"\"\n",
    "    return np.sqrt(2 * ((s + b + 10) * np.log(1 + s / (b + 10)) - s))\n",
    "\n",
    "sumw = df.groupby(\"Label\").Weight.sum()\n",
    "nsig_tot = sumw[\"s\"]\n",
    "nbkg_tot = sumw[\"b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6c15e1-0a37-463f-92d0-b202f09270fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dl_test = DataLoader(\n",
    "    torch.tensor(X_test, dtype=torch.float32),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ca2d4a-50e4-4aaa-a3eb-127a6af5a63b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(dl, device=\"cpu\"):\n",
    "    out = []\n",
    "    for X in dl:\n",
    "        X = X.to(device)\n",
    "        with torch.no_grad():\n",
    "            out.append(model(X).sigmoid().cpu()) # <- need to apply activation function here\n",
    "    return torch.cat(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea6ac13-15d4-4ef2-ba49-cb883cd253a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p_test = predict(dl_test, device=device).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb65a49-bdc2-4df4-b5f8-924b4e879111",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, p_test, sample_weight=weight_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01636cf7-8600-45ca-810c-7e5a318aa537",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thr = roc_curve(y_test, p_test, sample_weight=weight_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a80e96e-6645-4095-bc0e-17b5a28b8c5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ams(tpr * nsig_tot, fpr * nbkg_tot).max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
