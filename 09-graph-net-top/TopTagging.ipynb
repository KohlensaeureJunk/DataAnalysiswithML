{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# A particle physics application for Neural Networks: Top quark tagging\n",
    "\n",
    "This tutorial uses a lot of material from Lisa Benato and Dirk Kr√ºcker (https://github.com/dkgithub/wuhan_DL_labs)\n",
    "\n",
    "Notebook based on [CNNTopTagging.ipynb from LMU course](https://github.com/fuenfundachtzig/LMU_DA_ML/blob/master/CNNTopTagging.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### The Standard Model and the top quark\n",
    "\n",
    "<br>\n",
    "<img src=\"figures/top_tagging/SM.png\" width=\"400\" >\n",
    "\n",
    "The **Standard Model** of elementary particles represents our knowledge of the microscopic world. It describes the matter constituents (quarks and leptons) and their interactions (mediated by bosons), that are the electromagnetic, the weak and the strong interactions.\n",
    "\n",
    "Among all these particles, the **top quark** still represents a very peculiar case. It is the heaviest known elementary particle (mass of 172.5 GeV) and it has a very short lifetime ($10^{-25}$ seconds): this means we can only see its decay products. It has been discovered in 1995 by the CDF and D0 experiments at Tevatron (Fermilab, Chicago). The top quark is considered a key particle to searches for new physics beyond the Standard Model and to precision measurements.\n",
    "\n",
    "The ideal tool for measuring the top quark properties is a particle collider. The **Large Hadron Collider** (LHC), situated nearby Geneva, between France and Switzerland, is the largest proton-proton collider ever built on Earth. It consists of a 27 km circumference ring, where proton beams are smashed at a centre-of-mass energy of 13 TeV (99.999999% the speed of light). At the LHC, 40 Million collisions / second occur, yielding an enormous amount of data. Thanks to these data, **ATLAS** and **CMS** experiments discovered the missing piece of the Standard Model, the Higgs boson, in 2012.\n",
    "\n",
    "During a collision, the energy is so high that protons are \"broken\" into their fundamental components, i.e. **quarks** and **gluons**, that can interact, producing particles that we don't observe in our everyday life, such as the top quark. The production of a top quark is, by the way, a relatively \"rare\" phenomenon, since there are other physical processes that occur way more often, such as those initiated by strong interaction, producing lighter quarks (such as up, down, strange quarks). In high energy physics, we speak about the **cross-section** of a process. We say that the top quark production has a smaller cross-section than the production of light quarks.\n",
    "\n",
    "The experimental consequence is that distinguishing the decay products of a top quark from a light quark can be extremely difficult, given that the latter process has a way larger probability to happen.\n",
    "\n",
    "### Experimental signature of top quark in a particle detector\n",
    "\n",
    "Let's first understand what are the experimental signatures and how our detectors work. This is a sketch of the CMS experiment.\n",
    "\n",
    "<br>\n",
    "<img src=\"figures/top_tagging/EPS_CMS_Slice.png\" width=\"1000\" >\n",
    "\n",
    "A collider detector is organized in layers: each layer is able to distinguish and measure different particles and their properties. For example, the silicon tracker detects each particle that is charged. The electromagnetic calorimeter detects photons and electrons. The hadronic calorimeter detects hadrons (such as protons and neutrons). The muon chambers detect muons (that have a long lifetime and travel through the inner layers).\n",
    "\n",
    "Our physics problem consists into detecting the so-called \"hadronic decay\" of a top quark. The decay chain is sketched here: the top quark decays into a bottom quark and into a $W$ boson, that in turn decays into light quarks (in the picture, up and down quarks).\n",
    "\n",
    "<br>\n",
    "<img src=\"figures/top_tagging/top.png\" width=\"500\" >\n",
    "\n",
    "Our background is, instead, represented by light quark (or quarks) produced by the strong interaction (in jargon, QCD). Here we have a sketch of one possible background event.\n",
    "\n",
    "<br>\n",
    "<img src=\"figures/top_tagging/QCD.png\" width=\"200\" >\n",
    "\n",
    "#### Jets\n",
    "\n",
    "Without going into the theoretical details, the nature of particles experiencing the strong interaction (like quarks) is such that they cannot travel free, but they are forced to be \"confined\" into hadrons. One hadron can be seen as a \"combination\" of quarks. Let's think about the electromagnetic interaction: a positive charge and a negative charge are attracted to each other, and they will tend to form a state that is neutral under the electromagnetic interaction. Analogously, quarks try to combine together, forming a bond state that is neutral under the strong interaction. This process is called **hadronization**, and it has a very important consequence. Quarks won't appear as single isolated particles in a detector, but rather as **jets** of particles.\n",
    "\n",
    "There are many different algorithms that are able to reconstruct quarks (and gluons) as jets (i.e., anti-$k_T$ algorithm [arXiv:0802.1189](https://arxiv.org/abs/0802.1189)). They basically loop over the shower of particles produced by the hadronization, trying to cluster them together as one single entity. The algorithms are designed such in a way that the momentum of the clustered jet is proportional to the initial energy of the quark. A sketch giving an intuitive idea of a jet is displayed here (Klaus Rabbertz, KIT):\n",
    "\n",
    "<br>\n",
    "<img src=\"figures/top_tagging/Rabbertz_from_quark_to_rec_jet.png\" width=\"500\" >\n",
    "\n",
    "#### Jets substructure\n",
    "\n",
    "Many physically motivated approaches have been used in the past to distinguish a jet initiated by a top quark from jets due to QCD. One remarkable property is the so-called **jet substructure**. The idea is to try to distinguish how many \"sub-jets\" are included in a jet. Out of our sketches presented before, since the top quark decays into three separated quarks, we would expect it to show a three-pronged sub-structure. QCD, on the other hand, is mainly due to single quark/gluon radiation, hence it shows a one-pronged sub-structure. One largely used approach to study the jet substructure is the so called *n-subjettiness* ([arxiv:1011.2268](https://arxiv.org/abs/1011.2268))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jet images -  a nail for the hammer?\n",
    "\n",
    "One Ansatz is to use techniques from image recognition with neural networks, namely convolutional neural networks. This requires to transform our   jet constituent data into an image.\n",
    "\n",
    "We unroll the cylindrical surface of the detector along the azimuthal and longitudinal coordinates and subdivide the area into pixels. The pixel values then correspond to the energy deposits (component transverse to the beam direction) of our jet constituents. Here we will use this as a grayscale image, but in principle one could use multiple features, similar to the colours of images with more information than just the energy (e.g. number of particles, energy for neutral and charged particles as done in https://arxiv.org/abs/1612.01551)\n",
    "\n",
    "<br>\n",
    "<img src=\"figures/top_tagging/images_jets.png\" width=\"800\" >\n",
    "\n",
    "(Figure from https://arxiv.org/abs/1612.01551)\n",
    "\n",
    "We do not further discuss CNN in this notebook, but if you are interested please check the original notebook [CNNTopTagging.ipynb](https://github.com/fuenfundachtzig/LMU_DA_ML/blob/master/CNNTopTagging.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Deep Set method to top-tagging dataset\n",
    "\n",
    "Sets are a nice representation for objects in particles physics. Let's apply this to the jet constituents of the TopTagging dataset.\n",
    "\n",
    "We have prepared a subset of this dataset in original form containing the 4-momenta (Energy, px, py, pz) of up to 200 jet constituents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, GlobalAveragePooling1D, Masking\n",
    "from tensorflow.keras.callbacks import History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_tagging_path = \"top_tagging_with_adjacency.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(top_tagging_path):\n",
    "    import requests\n",
    "    url = \"https://cloud.physik.lmu.de/index.php/s/AtESAET6JK6DiWZ/download\"\n",
    "    res = requests.get(url)\n",
    "    with open(top_tagging_path, \"wb\") as f:\n",
    "        f.write(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "npz_file = np.load(top_tagging_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = npz_file[\"jet_4mom\"]\n",
    "y = npz_file[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have 10k events, each with 200 4-dim particles. Missing entries are set to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reuse the `JetScaler` we defined for the Higgs Dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class JetScaler:\n",
    "    def __init__(self, mask_value=-999):\n",
    "        self.mask_value = mask_value\n",
    "        self.scaler = RobustScaler()\n",
    "    \n",
    "    def fill_nan(self, X):\n",
    "        \"replace missing values by nan\"\n",
    "        X[(X == self.mask_value).all(axis=-1)] = np.nan\n",
    "        \n",
    "    def fit(self, X):\n",
    "        X = np.array(X) # copy\n",
    "        self.fill_nan(X)\n",
    "        X = X.reshape(-1, X.shape[-1]) # make 2D\n",
    "        self.scaler.fit(X)\n",
    "        \n",
    "    def transform(self, X):\n",
    "        orig_shape = X.shape\n",
    "        X = np.array(X).reshape(-1, X.shape[-1])\n",
    "        self.fill_nan(X)\n",
    "        X = self.scaler.transform(X)\n",
    "        X = np.nan_to_num(X, 0) # replace missing values by 0\n",
    "        return X.reshape(*orig_shape) # turn back into 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "scaler = JetScaler(mask_value=0)\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the NN we can use a simple Sequential stack of layers since we only use the jet constituents as inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    Masking(input_shape=X_train.shape[1:]),\n",
    "    Dense(100, activation=\"relu\"),\n",
    "    Dense(100, activation=\"relu\"),\n",
    "    Dense(100, activation=\"relu\"),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(100, activation=\"relu\"),\n",
    "    Dense(100, activation=\"relu\"),\n",
    "    Dense(100, activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we were can use a [Masking](https://stackoverflow.com/questions/75410827/how-does-masking-work-in-tensorflow-keras) layer to ignore missing values. \n",
    "*(Important: Only possible because the sequence is never completely empty.)*\n",
    "\n",
    "Again, the first layers operate independently on each constituent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = History()\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    callbacks=[history],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thr = roc_curve(y_test, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_top_tagging_performance(fpr, tpr):\n",
    "    plt.plot(tpr, 1. / fpr)\n",
    "    plt.ylabel(\"QCD jet rejection\")\n",
    "    plt.xlabel(\"Top quark jet efficiency\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.grid()\n",
    "\n",
    "    print(\"Top quark jet selection efficiency at 10^3 QCD jet rejection: \", np.max(tpr[fpr < 0.001]))\n",
    "    print(\"QCD jet rejection at 30% Top quark jet efficiency: \", 1. / np.min(fpr[tpr > 0.3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_top_tagging_performance(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h2>Exercise 1</h2>\n",
    "    As usual, play with the options: number of layers, number of neurons, switch off masking, ...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "name": "CNNTopTagging.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
