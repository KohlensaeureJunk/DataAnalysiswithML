{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f540d8c5-2c20-49d9-937c-e1214e47d1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063409f7-c113-4df0-a122-950384169a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(noise=0.25, n_samples=100, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a37740d-2c06-4413-b4ff-d4db54168210",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(*X[y==0].T)\n",
    "plt.scatter(*X[y==1].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19484b8f-7233-4140-864c-274c185b2b0f",
   "metadata": {},
   "source": [
    "# With sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cbdcc1-dd68-41e0-9f6a-95a800e6890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f57832b-661c-4ed6-a036-1839bbcff678",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=(32,), solver=\"sgd\", batch_size=len(X), learning_rate_init=0.5\n",
    ").fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c833d89d-22be-4431-a0b7-22987165308b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.loss_curve_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f499f9-458a-4972-9e35-d2b08de77347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_classifier(predict, xmin, xmax, ymin, ymax, **kwargs):\n",
    "    xx, yy = np.meshgrid(\n",
    "        np.linspace(xmin, xmax, 100),\n",
    "        np.linspace(ymin, ymax, 100),\n",
    "    )\n",
    "    X = np.stack([xx, yy], axis=-1).reshape(-1, 2)\n",
    "    zz = predict(X).reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, zz, levels=100, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e4691e-6bb6-4670-bb75-c2a16ee21cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_classifier(lambda x: model.predict_proba(x)[:, 1], -2, 2.5, -2, 2.5, cmap=\"RdBu\")\n",
    "plt.scatter(*X[y==0].T, color=\"red\")\n",
    "plt.scatter(*X[y==1].T, color=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9006c5a9-a851-48e9-b12e-33ba8fc557ef",
   "metadata": {},
   "source": [
    "# With pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588e6a9c-b3ff-47d8-aa34-08c1a401c63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55c2557-bab9-4658-9c0f-c900924a9b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ae710e-ac79-4475-b104-d009ed9cc288",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = 32\n",
    "model = nn.Sequential(nn.Linear(2, neurons), nn.ReLU(), nn.Linear(neurons, 1), nn.Sigmoid())\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38ebea0-5d75-48b3-b6e4-b25b59d05500",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c22e17-7968-48c4-9eb4-f6bb3dbb7afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "for i in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(X).squeeze(1)\n",
    "    loss = nn.functional.binary_cross_entropy(y_pred, y)\n",
    "    loss.backward()\n",
    "    history.append(loss.detach().numpy())\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a30eb2-0be9-4931-870a-4c78fa534f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7db594-01fb-4133-b20a-acc653cc1364",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    visualize_classifier(\n",
    "        lambda x: model(torch.tensor(x, dtype=torch.float32)).squeeze().numpy(),\n",
    "        -2, 2.5, -2, 2.5,\n",
    "        cmap=\"RdBu\"\n",
    "    )\n",
    "plt.scatter(*X[y==0].T, color=\"red\")\n",
    "plt.scatter(*X[y==1].T, color=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc7a798-a9b9-4646-a316-d0bcc67d9517",
   "metadata": {},
   "source": [
    "# With torch (manual optimizer)\n",
    "\n",
    "need to talk about backprop and vjp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf518893-3564-42c1-b2bf-8febaed4f80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(0, 2*np.pi, 100, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aaf1e1-0e9a-43d8-9778-148bb4db4ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = torch.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140f3e8c-2ae1-4156-a1e3-1275906f1ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "yy.backward(torch.ones_like(yy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7545c9-454c-4db9-9120-6dc45ae5bc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x.detach(), yy.detach())\n",
    "plt.plot(x.detach(), x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23553fac-d239-4349-b7c0-97072e91ed67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(2, neurons), nn.ReLU(), nn.Linear(neurons, 1), nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3014659c-91a2-469a-b4b7-40064868a574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(lr=1):\n",
    "    with torch.no_grad():\n",
    "        for par in model.parameters():\n",
    "            par.add_(-lr * par.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8811713-24a0-4132-b2f5-89b898930f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "for i in range(1000):\n",
    "    model.zero_grad()\n",
    "    y_pred = model(X).squeeze(1)\n",
    "    loss = nn.functional.binary_cross_entropy(y_pred, y)\n",
    "    loss.backward()\n",
    "    step()\n",
    "    history.append(loss.detach().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fa73e1-d7d7-4313-b658-e5a102c7d285",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9be18fd-8d3b-4881-9ee5-af5b7c66c2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    visualize_classifier(lambda x: model(torch.from_numpy(x).float()).squeeze(1), -2, 2.5, -2, 2.5, cmap=\"RdBu\")\n",
    "plt.scatter(*X[y==0].T, color=\"red\")\n",
    "plt.scatter(*X[y==1].T, color=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a49f88e-4e83-4283-b641-58c5b1f6e28b",
   "metadata": {},
   "source": [
    "# With torch (manual backpropagation)\n",
    "\n",
    "to see this a bit better we also implement the model step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7e44b3-46d3-4e28-b7e9-3e096b043af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = (torch.randn(2, neurons) * 0.1).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4c3db8-d72b-4c1f-a704-ad327f497ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = X @ w1; z1.retain_grad()\n",
    "z1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e074fcc-4762-4455-b2c0-de4a0b01c60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = z1.relu(); a1.retain_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f109d2ec-c33b-4b14-bcba-d9ef352a5ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = (torch.randn(neurons, 1) * 0.1).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71bbd96-83b1-4036-b189-ba2c6971186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "z2 = a1 @ w2; z2.retain_grad()\n",
    "z2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06804efd-680c-436a-a760-cb1ed525cab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "z2 = z2.squeeze(1); z2.retain_grad()\n",
    "z2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888a4c4e-c333-4107-a980-d3ad6f77a29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.mean((y - z2) ** 2)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80d032b-5e7d-4396-b962-54600734b745",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ff90ca-c80d-4d68-842c-aa28f2d65ccd",
   "metadata": {},
   "source": [
    "e.g. `dz2` means gradient of loss wrt all components of `z2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9dce05-fc2f-41d8-a474-385e145b545c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dz2 = - 2 / len(z2) * (y - z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc8d3f6-c425-4ddf-ba28-06f3d6ec4a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "(z2.grad == dz2).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d692c69b-abc7-4d55-9818-cfc909b25c8c",
   "metadata": {},
   "source": [
    "... figure out what grad of matrix multiply is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af681a4-817e-47a4-af78-6077c3acc2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dz2.shape, a1.shape, w2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65175bac-0fdd-4c83-ab8f-cf826c85f106",
   "metadata": {},
   "outputs": [],
   "source": [
    "dz2.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c80b46-9bd5-4d61-91ad-b02d6f72c8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dw2 = a1.T @ dz2.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdba22dd-6798-49f5-9f3d-b07a4c9534ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dw2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefc66d2-4913-47b0-8894-f0f4d8eacff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dw2 == w2.grad).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b3538f-15d0-4b43-a50b-0b2b4c5a5da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "da1 = dz2.unsqueeze(1) @ w2.T\n",
    "da1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8f872c-25de-431c-97fc-8e5293459f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(da1 == a1.grad).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfa7e85-e2e8-46a0-8909-886cad0818e9",
   "metadata": {},
   "source": [
    "what is the derivative of relu?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6e16e1-1acb-4f8c-99c9-1d086fbc968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dz1 = (z1 > 0) * da1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7021fc7-505b-4fe4-8b7c-eb703440156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dz1 == z1.grad).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485d1f4a-fa4c-474d-8a2c-cf5237c7a7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.shape, dz1.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991ddaa2-a9cb-4371-9d58-4e9d107e6338",
   "metadata": {},
   "outputs": [],
   "source": [
    "dw1 = X.T @ dz1\n",
    "dw1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a1e33e-092a-4b13-9043-50ddaffe656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dw1 == w1.grad).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abeeb75-764e-460b-a907-683c7fbf1cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameters\n",
    "w1 = torch.randn(2, neurons) * 0.1\n",
    "w2 = torch.randn(neurons, 1) * 0.1\n",
    "\n",
    "# training loop\n",
    "lr = 0.1\n",
    "history = []\n",
    "for i in range(100):\n",
    "    # forward\n",
    "    z1 = X @ w1\n",
    "    a1 = torch.relu(z1)\n",
    "    z2 = a1 @ w2\n",
    "    z2 = z2.squeeze(1)\n",
    "    loss = torch.mean((y - z2) ** 2)\n",
    "    \n",
    "    history.append(loss.item())\n",
    "\n",
    "    # backward\n",
    "    dz2 = - 2 / len(z2) * (y - z2)\n",
    "    dw2 = a1.T @ dz2.unsqueeze(1)\n",
    "    da1 = dz2.unsqueeze(1) @ w2.T\n",
    "    dz1 = (z1 > 0) * da1\n",
    "    dw1 = X.T @ dz1\n",
    "\n",
    "    # gradient update\n",
    "    for par, grad in [(w1, dw1), (w2, dw2)]:\n",
    "        par.add_(-lr * grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46ecb54-dd5c-4792-9400-68e311794262",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352e31db-c23a-4d5c-9a44-277e5c88c331",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    visualize_classifier(\n",
    "        lambda x: torch.relu(torch.from_numpy(x).float() @ w1) @ w2,\n",
    "        -2, 2.5, -2, 2.5, cmap=\"RdBu\"\n",
    "    )\n",
    "plt.scatter(*X[y==0].T, color=\"red\")\n",
    "plt.scatter(*X[y==1].T, color=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d6d6ef-a0e0-4d8b-a7e7-24fe96b807ab",
   "metadata": {},
   "source": [
    "implement bias and sigmoid activation\n",
    "\n",
    "bias vjp: gradient of loss wrt to bias always one, so vjp is sum over incoming grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b706aad-2485-4469-87b4-b52f88ff00db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameters\n",
    "w1 = torch.randn(2, neurons) * 0.1\n",
    "w2 = torch.randn(neurons, 1) * 0.1\n",
    "b1 = torch.randn(neurons) * 0.1\n",
    "b2 = torch.randn(1) * 0.1\n",
    "\n",
    "# training loop\n",
    "lr = 0.1\n",
    "history = []\n",
    "for i in range(100):\n",
    "    # forward\n",
    "    z1 = X @ w1 + b1\n",
    "    a1 = z1.relu()\n",
    "    z2 = a1 @ w2 + b2\n",
    "    z2 = z2.squeeze(1)\n",
    "    loss = torch.mean((y - z2) ** 2)\n",
    "    \n",
    "    history.append(loss.item())\n",
    "\n",
    "    # backward\n",
    "    dz2 = - 2 / len(z2) * (y - z2)\n",
    "    dw2 = a1.T @ dz2.unsqueeze(1)\n",
    "    db2 = dz2.sum()\n",
    "    da1 = dz2.unsqueeze(1) @ w2.T\n",
    "    dz1 = (z1 > 0) * da1\n",
    "    dw1 = X.T @ dz1\n",
    "    db1 = dz1.sum() * torch.ones_like(b1)\n",
    "\n",
    "    # gradient update\n",
    "    for par, grad in [(w1, dw1), (w2, dw2), (b1, db1), (b2, db2)]:\n",
    "        par.add_(-lr * grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3340d1-fd59-4a2e-a521-a15edce0a96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2f7874-49f1-4eb3-adb2-aeffce292070",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    visualize_classifier(\n",
    "        lambda x: torch.relu(torch.from_numpy(x).float() @ w1 + b1) @ w2 + b2,\n",
    "        -2, 2.5, -2, 2.5, cmap=\"RdBu\"\n",
    "    )\n",
    "plt.scatter(*X[y==0].T, color=\"red\")\n",
    "plt.scatter(*X[y==1].T, color=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c61b17-0766-4cec-a992-4055515da2f5",
   "metadata": {},
   "source": [
    "better, but still not great, let's go for sigmoid and binary crossentropy\n",
    "\n",
    "need to talk about the grads for these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8316ec0-516e-452e-b54b-fa30459420ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameters\n",
    "w1 = torch.randn(2, neurons) * 0.1\n",
    "w2 = torch.randn(neurons, 1) * 0.1\n",
    "b1 = torch.randn(neurons) * 0.1\n",
    "b2 = torch.randn(1) * 0.1\n",
    "\n",
    "# training loop\n",
    "lr = 1.0\n",
    "eps = 1e-8 # constant to avoid division by/log of zero\n",
    "history = []\n",
    "for i in range(1000):\n",
    "    # forward\n",
    "    z1 = X @ w1 + b1\n",
    "    a1 = torch.relu(z1)\n",
    "    z2 = a1 @ w2 + b2\n",
    "    a2 = torch.sigmoid(z2.squeeze(1))\n",
    "    loss = -torch.mean(y * torch.log(a2 + eps) + (1 - y) * torch.log(1 - a2 + eps))\n",
    "\n",
    "    history.append(loss.detach().item())\n",
    "\n",
    "    # backward\n",
    "    da2 = -1 / len(a2) * (y / (a2 + eps) - (1 - y) / (1 - a2 + eps))\n",
    "    dz2 = (da2 * a2 * (1 - a2)).reshape(z2.shape)\n",
    "    dw2 = a1.T @ dz2\n",
    "    db2 = dz2.sum(axis=0)\n",
    "    da1 = dz2 @ w2.T\n",
    "    dz1 = (z1 > 0) * da1\n",
    "    dw1 = X.T @ dz1\n",
    "    db1 = dz1.sum(axis=0) * torch.ones_like(b1)\n",
    "\n",
    "    # gradient update\n",
    "    for par, grad in [(w1, dw1), (w2, dw2), (b1, db1), (b2, db2)]:\n",
    "        par.add_(-lr * grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e64acc2-53fc-4a6b-b72a-a2a12c61b6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cdadbd-8b4c-4efc-a1ee-42c827baa4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    visualize_classifier(\n",
    "        lambda x: ((torch.from_numpy(x).float() @ w1 + b1).relu() @ w2 + b2).sigmoid(),\n",
    "        -2, 2.5, -2, 2.5, cmap=\"RdBu\"\n",
    "    )\n",
    "plt.scatter(*X[y==0].T, color=\"red\")\n",
    "plt.scatter(*X[y==1].T, color=\"blue\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
