{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2515a38f-38ff-4dc9-af72-0adea48d8dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a22b861-fc2f-4a0d-a8cd-78c0813c8d53",
   "metadata": {},
   "source": [
    "# Deep sets and graph networks\n",
    "\n",
    "Notebook based on [DeepSetsAndGraphNetworks.ipynb from LMU course](https://github.com/fuenfundachtzig/LMU_DA_ML/blob/master/DeepSetsAndGraphNetworks.ipynb)\n",
    "\n",
    "The ML models we have looked at so far make the assumption that we have a fixed-dimensional vector of input features. In reality that might not always be the case. Some examples:\n",
    "\n",
    "* Sequences (text, audio, video)\n",
    "* Point clouds (e.g. points in 3D space)\n",
    "* Lists of objects (e.g. particles in a collision)\n",
    "* Graphs with different numbers of nodes and different numbers of connections for each node\n",
    "\n",
    "For sequences one approach are recurrent neural networks (RNNs) that utilize a state that gets updated as it iteratively processes input. However, these still need a defined ordering of the inputs and they have certain disadvantages (most prominently difficulty to model \"long-range\" correlations between inputs and difficulty to parallelize since they are sequential in nature).\n",
    "\n",
    "Another approach are models that apply **permutation invariant** transformations on the inputs. Both deep sets and graph networks make use of this. The nowadays (2023) also very popular [**transformers**](https://arxiv.org/abs/1706.03762) can be viewed as graph networks where all nodes are connected to each other.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbc7889-701f-4752-8909-91e59b083552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, GlobalAveragePooling1D, Masking\n",
    "from tensorflow.keras.callbacks import History"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994ce54e-afe2-4111-a836-6e8f979844a8",
   "metadata": {},
   "source": [
    "## Graph convolutions/Graph neural networks\n",
    "\n",
    "Similar to convolutional networks where we update the state of each pixel by aggregating over neigboring pixels we can perform a *graph convolution* by aggregating over neighboring nodes in a graph:\n",
    "\n",
    "![cnn vs gcn](figures/cnn_vs_gcn.jpg)\n",
    "\n",
    "(figure from https://zhuanlan.zhihu.com/p/51990489)\n",
    "\n",
    "In the \"Deep sets\" language such a graph convolution corresponds to a *permutation equivariant* tranformation of the set of nodes, since it also does not depend on the ordering if the aggregation is done in a permutation invariant way (e.g. sum/mean/min/max).\n",
    "\n",
    "A rather simple implementation is given by the update rule introduced in [arXiv:1609.02907](https://arxiv.org/abs/1609.02907)\n",
    "\n",
    "$ H^{(l+1)} = \\sigma(\\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}H^{(l)}W^{(l)}) $\n",
    "\n",
    "where $A$ is the *adjacency matrix*, $D$ the *degree matrix*,  $H^{(l)}$ the hidden state of layer $l$ and $W^{(l)}$ the weight matrix of the layer $l$. The tilde above $A$ and $D$ indicates that self-loops were added (all nodes are neighbors of themselves).\n",
    "\n",
    "An equivalent formulation is\n",
    "\n",
    "$ h_i^{(l+1)} = \\sigma\\left(\\sum\\limits_{j\\in\\mathcal{N}(i)}\\frac{1}{c_{ij}}h^{(l)}_j W^{(l)}\\right) $\n",
    "\n",
    "where $ \\mathcal{N(i)} $ is the set of neighbors of node $i$ and $c_{ij} = \\sqrt{N_i}\\sqrt{N_j}$ with $N_i$ being the number of neigbors of node $i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470499fd-1c46-4c0f-ac61-3d27d9084a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_adjacency(adj):\n",
    "    \"\"\"\n",
    "    calculate outer product of sqrt(degree vector) and multiply with adjaceny matrix\n",
    "    \n",
    "    this corresponds to the D^{1/2}AD^{1/2} normalization suggested in Kipf & Welling (arXiv:1609.02907)\n",
    "    \"\"\"\n",
    "    deg_diag = tf.reduce_sum(adj, axis=2)\n",
    "    deg12_diag = tf.where(deg_diag > 0, deg_diag ** -0.5, 0)\n",
    "    return (\n",
    "        tf.matmul(\n",
    "            tf.expand_dims(deg12_diag, axis=2),\n",
    "            tf.expand_dims(deg12_diag, axis=1),\n",
    "        )\n",
    "        * adj\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7904fe3e-784b-442b-b70a-218d5b064d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConv(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Simple graph convolution. Should be equivalent to Kipf & Welling (arXiv:1609.02907)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, units, activation=\"relu\"):\n",
    "        super().__init__()\n",
    "        self.dense = tf.keras.layers.Dense(units)\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        feat, adjacency = inputs\n",
    "        return self.activation(tf.matmul(normalize_adjacency(adjacency), self.dense(feat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a71b908-a775-491c-81f0-a141d8957b5c",
   "metadata": {},
   "source": [
    "One question is now - what is the graph in our dataset? It might make sense to define the graph by taking a certain number of nearest neighbors in the $\\eta-\\phi$ plane as used to define the image pixels.\n",
    "We prepared adjacency matrices for 7 nearest neigbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90da5a0e-71a7-4ae7-85ea-51c00f820ecf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_tagging_path = \"top_tagging_with_adjacency.npz\"\n",
    "import os\n",
    "if not os.path.exists(top_tagging_path):\n",
    "    import requests\n",
    "    url = \"https://cloud.physik.lmu.de/index.php/s/AtESAET6JK6DiWZ/download\"\n",
    "    res = requests.get(url)\n",
    "    with open(top_tagging_path, \"wb\") as f:\n",
    "        f.write(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ca534a-465f-43a2-85b7-491632cbac5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "npz_file = np.load(top_tagging_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc61f82c-6e00-4163-b0ff-4457695e1d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = npz_file[\"jet_4mom\"]\n",
    "y = npz_file[\"y\"]\n",
    "A = npz_file[\"adj\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93204ac4-9b4a-483c-b400-df7269a10458",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77331119-5900-4ff0-9fb4-c244e4e8791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ptetaphi(X):\n",
    "    px = X[..., 1]\n",
    "    py = X[..., 2]\n",
    "    pz = X[..., 3]\n",
    "    pt = np.hypot(px, py)\n",
    "    eta = np.arcsinh(pz / pt)\n",
    "    phi = np.arcsin(py / pt)\n",
    "    return np.stack([pt, eta, phi], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54d0044-f86c-4cb8-a70e-aa6420f4604b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(x, a):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    nconst = (~(a == 0).all(axis=-1)).sum()\n",
    "    print(f\"{nconst=}\")\n",
    "    x = x[:nconst]\n",
    "    x = ptetaphi(x)\n",
    "    plt.scatter(x[:, 1], x[:, 2], s=100)\n",
    "    for i in range(nconst):\n",
    "        for j in range(nconst):\n",
    "            if a[i, j] or a[j, i]:\n",
    "                plt.plot([x[i, 1], x[j, 1]], [x[i, 2], x[j, 2]], color=\"C0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcba287b-ff68-453a-b342-7ab33b33140c",
   "metadata": {},
   "source": [
    "Let's plot a few random graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6680d2-87e6-49a6-a20a-641d02b48b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(0, len(X))\n",
    "plot_graph(X[i], A[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c8efca-7d7d-4a0e-9af3-2467c3daecda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class JetScaler:\n",
    "    def __init__(self, mask_value=-999):\n",
    "        self.mask_value = mask_value\n",
    "        self.scaler = RobustScaler()\n",
    "    \n",
    "    def fill_nan(self, X):\n",
    "        \"replace missing values by nan\"\n",
    "        X[(X == self.mask_value).all(axis=-1)] = np.nan\n",
    "        \n",
    "    def fit(self, X):\n",
    "        X = np.array(X) # copy\n",
    "        self.fill_nan(X)\n",
    "        X = X.reshape(-1, X.shape[-1]) # make 2D\n",
    "        self.scaler.fit(X)\n",
    "        \n",
    "    def transform(self, X):\n",
    "        orig_shape = X.shape\n",
    "        X = np.array(X).reshape(-1, X.shape[-1])\n",
    "        self.fill_nan(X)\n",
    "        X = self.scaler.transform(X)\n",
    "        X = np.nan_to_num(X, 0) # replace missing values by 0\n",
    "        return X.reshape(*orig_shape) # turn back into 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67314797-44ec-4b18-ae8c-78a5a25b54ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, A_train, A_test = train_test_split(X, y, A)\n",
    "scaler = JetScaler(mask_value=0)\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede25380-9593-460f-86f3-ad92796d79ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(units=100, num_nodes=200, num_features=4):\n",
    "    adjacency_input = Input(shape=(num_nodes, num_nodes), name='adjacency')\n",
    "    feature_input = Input(shape=(num_nodes, num_features), name='features')\n",
    "\n",
    "    # constituent-level transformations\n",
    "    p = feature_input\n",
    "    for i in range(3):\n",
    "        p = Dense(units, activation=\"relu\")(p)\n",
    "\n",
    "    for i in range(3):\n",
    "        p = GraphConv(units, activation=\"relu\")([p, adjacency_input])\n",
    "\n",
    "    x = GlobalAveragePooling1D()(p)\n",
    "\n",
    "    # event-level transformations\n",
    "    for i in range(3):\n",
    "        x = Dense(units, activation=\"relu\")(x)\n",
    "\n",
    "    output = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    return tf.keras.models.Model(\n",
    "        inputs=[adjacency_input, feature_input],\n",
    "        outputs=[output]\n",
    "    )\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a23d5b3-b8cc-4924-b27d-10536750d8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c2c96f-73af-4977-9ea5-2a3809b9cc5f",
   "metadata": {},
   "source": [
    "**Interactive plotting needs extra tools, here the resulting plot:**\n",
    "\n",
    "![](figures/keras_GN_model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d4b82f-2571-4419-be82-9697d56c0bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7834ecc-5a7f-45e1-8654-2d09c26c836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = History()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1b6674-3d8d-4595-9e7c-e878299b2a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    {\"features\": X_train, \"adjacency\": A_train},\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    callbacks=[history]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09607904-5cf7-4747-9499-e582ec257435",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246e7bd9-087a-4a5d-8fbc-644d75043ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.predict({\"features\": X_test, \"adjacency\": A_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9438c750-f32b-45ab-87b0-ceddedd10cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thr = roc_curve(y_test, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1a02a2-f0aa-4191-a809-a0d00c1e421a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_top_tagging_performance(fpr, tpr):\n",
    "    plt.plot(tpr, 1. / fpr)\n",
    "    plt.ylabel(\"QCD jet rejection\")\n",
    "    plt.xlabel(\"Top quark jet efficiency\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.grid()\n",
    "\n",
    "    print(\"Top quark jet selection efficiency at 10^3 QCD jet rejection: \", np.max(tpr[fpr < 0.001]))\n",
    "    print(\"QCD jet rejection at 30% Top quark jet efficiency: \", 1. / np.min(fpr[tpr > 0.3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2421315a-028e-4e25-a325-162e3cbe3a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_tagging_performance(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c06f37-64db-47a2-b3ed-6b11894bb657",
   "metadata": {},
   "source": [
    "Some Notes:\n",
    "\n",
    "- We made it quite hard here for the neural network by putting in really the raw 4-momentum information\n",
    "- Possible improvements:\n",
    "  - Go to the $\\eta-\\phi$ plane\n",
    "  - Transform coordinates to be relative to the jet center\n",
    "  - Use graph operations that depend on the distance between points instead of absolute position (e.g. [EdgeConv](https://arxiv.org/abs/1801.07829))\n",
    "  - just train longer and/or on more data (we only used 10k samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cab21cd-ec23-430e-9852-1d4fe3ee1bce",
   "metadata": {},
   "source": [
    "# Further possibilities\n",
    "\n",
    "We only touched the surface of what is possible with graph neural networks. In general, you can have arbitrary update rules that update in each step features of Nodes (V), Edges (e) and global aggregated features (u). Everyone of these 3 categories can receive input from any of the others:\n",
    "\n",
    "![graph network general update rule](figures/graph-network.png)\n",
    "\n",
    "(figure from [arXiv:1806.01261](https://arxiv.org/abs/1806.01261))\n",
    "\n",
    "More info/tutorials:\n",
    "\n",
    "http://tkipf.github.io/graph-convolutional-networks/  \n",
    "https://docs.dgl.ai/tutorials/models/1_gnn/1_gcn.html  \n",
    "https://docs.dgl.ai/generated/dgl.nn.pytorch.conv.GraphConv.html#\n",
    "\n",
    "For more advanced applications with graph neural networks have a look at specialized libraries:\n",
    "\n",
    "[Spektral (tensorflow)](https://graphneural.network/)  \n",
    "[DGL (mainly pytorch, but also tensorflow)](https://dgl.ai)  \n",
    "[PyTorch Geometric](https://pytorch-geometric.readthedocs.io)\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "If you actually want to implement graph networks, better consult these instead of manually building them. The examples in this tutorial are meant for educational purposes!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2299018c-3ceb-4093-8983-6051b1bfaca8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This top tagging dataset is a widely used benchmark dataset and used to test, compare, and optimize many different ML models, see \n",
    "[The Machine Learning Landscape of Top Taggers](https://arxiv.org/abs/1902.09914)\n",
    "\n",
    "A nice plot illustrating this (from G. Kasieczka):\n",
    "\n",
    "![top-tag-results.png](figures/top-tag-results.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7908bca4-283c-4fad-aa78-d02c519bd610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
