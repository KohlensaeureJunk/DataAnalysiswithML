{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn Introduction\n",
    "A number of Python packages provide implementations of  machine learning algorithms. \n",
    "**[Scikit-Learn](http://scikit-learn.org)** is one of the most popular.\n",
    "* it provides many of the common ML algorithms\n",
    "* well-designed, uniform API (programming interface)\n",
    "  * standardized and largely streamlined setup of the different models   \n",
    "    &rarr; easy to switch\n",
    "* good documentation\n",
    "\n",
    "The first example is based on the **[Iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set)**. This had already been introduced by famous statistician\n",
    "Ronald Fisher in 1936 and is used since then as instructive use case for classification. \n",
    "The data consists of\n",
    "* measurements of length and width of both sepal (Bl&uuml;tenkelch) and petal (Bl&uuml;te) \n",
    "* classification of Iris sub-species\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the usual setup: \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaboorn provides easy way to import iris dataset as pandas dataframe\n",
    "import seaborn as sns\n",
    "iris = sns.load_dataset('iris')\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization\n",
    "First step should always be some investigation of data properties, i.e.\n",
    "* basic statistical properties\n",
    "* visualization of distributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic statistics with pandas\n",
    "iris.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of single feature\n",
    "sns.histplot(data=iris,x='sepal_length',hue='species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined plot of 2 features\n",
    "sns.jointplot(data=iris,x='sepal_length',y='sepal_width', hue='species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined plot matrix of all features in dataframe\n",
    "#\n",
    "# will provide scatter plot of all combinations of numerical columns in dataframe\n",
    "# target (=species) can be given and will cause different colors\n",
    "sns.pairplot(iris, hue='species', diag_kind='hist', height=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "For use in sklearn with  **supervised learning** the first step is always to split  data into \n",
    "* table/matrix of **features**\n",
    "* list of **targets**\n",
    "\n",
    "And then split the data into **train** and **test** sample:\n",
    "* `train_test_split` function from sklearn\n",
    "* by default 75% for training and 25% for test and validation\n",
    "  * can be specified as parameter\n",
    "* randomized selection of entries  \n",
    "&rarr; inital order does not matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature matrix\n",
    "X=iris.loc[:,'sepal_length':'petal_width']\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target\n",
    "Y=iris.species\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break-up in train & test sample\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit knn Model, apply and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)\n",
    "#knn.fit(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy iris\n",
    "#X_new = np.array([[5, 4.9, 4, 1.2]])\n",
    "# recent version want same datatype for testing\n",
    "X_new = pd.DataFrame(np.array([[5, 4.9, 4, 1.2]]),columns=X.columns)\n",
    "# 2D format required, nrows vs ncolums (1x2)\n",
    "X_new.shape #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.predict(X_new) # apply model to new data point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test/evaluate model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "print(\"Test set predictions:\\n {}\".format(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test==y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use scilearn function for score\n",
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(\"Test set score: {:.3f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Further useful checks are the **classification report** and the **confusion matrix**,  \n",
    "they give detailed Info on mis-classifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(The meaning of `recall` etc. will be explained in a bit.) \n",
    "\n",
    "Another intuitive measure is the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "labels = np.unique(y_test)\n",
    "mat = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "print (labels, '\\n', mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Repeat with different settings for number of neighbors**\n",
    "\n",
    "**Usually high accuracy for Iris data**  \n",
    "as scatter plot suggested there is rather clear separation between species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Measure   Quality of Classification\n",
    "\n",
    "The above `classification_report` presented several parameters which are useful to quantify how well the qualification works.\n",
    "\n",
    "For these we need to introduce the following terms (assuming a classification with two classes *P* and *N*)\n",
    "* $t_p = $ true-positive: number of cases with predicted *P* and correct *P*\n",
    "* $t_n = $ true-negative: number of cases with predicted *N* and correct *N*\n",
    "* $f_p = $ false-positive: number of cases with predicted *P* and correct *N*\n",
    "* $f_n = $ false-negative: number of cases with predicted *N* and correct *P*\n",
    "\n",
    "![Confusion matrix](./figures/wikipedia_confusion_matrix.png \"More details: see Wikipedia article on confusion matrix\")\n",
    "\n",
    "\n",
    "Based on these, the parameters in the `classification_report`  are defined as:\n",
    "* `precision` (or `purity`): $ t_p / ( t_p + f_p ) $ , i.e. fraction of cases classified as *P* which are true *P*\n",
    "* `recall` (or `efficiency`): $ t_p / ( t_p + f_n ) $ , i.e. fraction of true *P* which are classified as *P*\n",
    "* `f1-score` : Mean of `precision` and `recall`\n",
    "\n",
    "See https://en.wikipedia.org/wiki/Precision_and_recall for a more detailed discussion\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Test further simple models\n",
    "\n",
    "### Gaussian Naive Bayes\n",
    "Also a conceptually simple model\n",
    "* basic assumption is that for each different category (*Iris-species*) the variables follow a Gaussian distribution.\n",
    "* In training the model determines parameters of these Gaussians\n",
    "* For classification then simply calculate probability of a given new Iris-data to be of species `i` based on Gaussian probability:\n",
    "$$ P(x) = \\frac{1}{{\\sigma_i \\sqrt {2\\pi } }}e^{{{ - \\left( {x - \\mu_i } \\right)^2 } \\, } \\left/ \\right. {\\, {2\\sigma_i ^2 }}}$$\n",
    "* where $\\mu_i$ and $\\sigma_i$ are mean and standarddeviation for respecitve variable and species `i`\n",
    "\n",
    "(We'll look at why it's called \"Bayes\" in a bit more detail [here](http://localhost:8888/notebooks/Higgs-Gaussian.ipynb#GaussianNB).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB # 1. choose model class\n",
    "model = GaussianNB()                       # 2. instantiate model\n",
    "model.fit(X_train, y_train)                # 3. fit model to data\n",
    "y_gnb = model.predict(X_test)              # 4. predict on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use scilearn function for score\n",
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(y_gnb, y_test)\n",
    "print(\"Test set score: {:.3f}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_gnb, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mat = confusion_matrix(y_test, y_gnb, labels=labels)\n",
    "print (labels,'\\n', mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Logistic Regression\n",
    "This method is similar to standard linear regression. However, it can be used for discrete dependent variables, i.e. classification use-cases.\n",
    "\n",
    "It is a rather simple, linear model: \n",
    "* logistic function: $f(x) = \\frac{1}{1+\\exp(-x)}$, $f(x): [-\\infty,\\infty] \\to [0,1]$\n",
    "* model: $y_i = f(x_i \\cdot \\beta) + \\epsilon_i$\n",
    "\n",
    "More info:\n",
    "* https://en.wikipedia.org/wiki/Logistic_regression \n",
    "* https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression # 1. choose model class\n",
    "model = LogisticRegression(max_iter=500)            # 2. instantiate model\n",
    "model.fit(X_train, y_train)                         # 3. fit model to data\n",
    "y_lr = model.predict(X_test)                        # 4. predict on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use scilearn function for score\n",
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(y_lr, y_test)\n",
    "print(\"Test set score: {:.3f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n",
    "\n",
    "SVM is another standard ML method, conceptually related to LR and kNN\n",
    "* Look for line/plane separating classes \n",
    "* Decision based on neighbouring elements:\n",
    "* Maximize margin to  ‘few-closest-elements (=Support Vectors)’\n",
    "* ‘linear SVM’ works  only for linear separation\n",
    "* ‘kernel SVM’ variant also for non-linear cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel='linear',gamma = \"auto\", random_state = 42)\n",
    "#model = SVC(kernel='rbf',gamma = \"auto\", random_state = 42)\n",
    "model.fit(X_train, y_train)                         # 3. fit model to data\n",
    "y_svm = model.predict(X_test)                        # 4. predict on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use scilearn function for score\n",
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(y_svm, y_test)\n",
    "print(\"Test set score: {:.3f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Probabilistic Classification\n",
    "\n",
    "In general models can not only be used to give single classification as in above examples but one can also get a list of probabilities for the different possible outcomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=500)            # 2. instantiate model\n",
    "model.fit(X_train, y_train)                         # 3. fit model to data\n",
    "\n",
    "yout=model.predict_proba(X_test)\n",
    "print (yout[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yout[y_lr != y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(y_lr[:5],y_test[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on type of problem this information can be further used to distinguish clear cases and those with overlapping classifications.\n",
    "\n",
    "Or one can use it to adjust trade-off between precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Classification for digit data\n",
    "\n",
    "Another classic example case for ML is handwritten digits data.\n",
    "\n",
    "A suitable dataset is included with sklearn, first we look into it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "digits.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is sklearn specific container, basically a list of 8x8 pixels images\n",
    "\n",
    "We plot a sub-set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(10, 10, figsize=(8, 8),\n",
    "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(digits.images[i], cmap='binary', interpolation='nearest')\n",
    "    ax.text(0.05, 0.05, str(digits.target[i]),\n",
    "            transform=ax.transAxes, color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot shows pixel image together with label (in green).\n",
    "\n",
    "* Some images are obvious\n",
    "* Others seem difficult "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at data from 1st image --> 2D table resembles 0\n",
    "print (digits.images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.images[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image data with sklearn:\n",
    "To use the data with sklearn as before we need a 2D structure: `samples x features` , i.e. the 8x8 images should be transformed into flat 1x64 array.   \n",
    "\n",
    "Already provided in Dataset, element `data` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (digits.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use as before just re-label\n",
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Digit classification\n",
    "\n",
    "multi-classification problem\n",
    "* conceptually no big difference to binary classification\n",
    "* models discussed are flexible to handle this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First kNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use scilearn function for score\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = knn.predict(X_test)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(\"Test set score: {:.3f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Detailed classification report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check confusion matrix**  \n",
    "very infomative for such a case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "mat = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(mat, square=True, annot=True, cbar=False)\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('true value');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### kNN performs really well!\n",
    "\n",
    "***\n",
    "#### Then  Gaussian Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "y_model = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = accuracy_score(y_model, y_test)\n",
    "print(\"Test set score: {:.3f}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, y_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = confusion_matrix(y_test, y_model)\n",
    "sns.heatmap(mat, square=True, annot=True, cbar=False)\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('true value');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GNB significantly worse, many more mis-ids!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Exercise: ####\n",
    "Also try the other models we discussed for classification, i.e. logistic regression and SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "261px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
