{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "271ee7ee-f324-49d8-b810-423f375f0bde",
   "metadata": {},
   "source": [
    "Also look at binomial significance? maybe start as motivation, then show general concept? also compare with rule of thumb formulas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2aeaf5-451a-481f-8584-99ba9b4d94c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c811a942-b791-417c-a876-9a59047bb25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll_hist(obs, exp):\n",
    "    \"\"\"\n",
    "    Negative log-likelihood for histogram with poisson distributed counts (up to constant terms)\n",
    "    \"\"\"\n",
    "    return np.sum(exp, axis=0) - np.sum(obs * np.log(exp), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9011120-a540-45be-b849-d0fac9d2d12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tau_from_db(b, db):\n",
    "    \"\"\"\n",
    "    Calculate tau (the ratio between expected background in the off and on region)\n",
    "    from the expected background and the absolute uncertainty on it.\n",
    "    \"\"\"\n",
    "    return b / (db ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6906bcf4-1bf5-4c59-89c4-cbe02c35f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 5\n",
    "delta_b = 2\n",
    "\n",
    "nobs = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674679b5-682e-43c0-b158-3009c701da86",
   "metadata": {},
   "source": [
    "p-value for rejecting the null hypothesis of no signal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c59b52-b544-4438-8c17-0b95ba1c7db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "non = nobs\n",
    "tau = tau_from_db(b, delta_b)\n",
    "noff = tau * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ebc821-5de6-4ff2-937a-67e5ec6541e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([np.array([1, 2]), np.array([3, 4])]).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79e5b7b-0803-4140-a159-f785a40e6837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll_onoff(non, noff, s, b, tau):\n",
    "    obs = np.array([non, noff])\n",
    "    exp = np.array([s + b, tau * b])\n",
    "    return nll_hist(obs, exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175d6868-ccff-449e-82cb-2f528f6d10bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nll_onoff(non, noff, s=0, b=b, tau=tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44d4f6c-4b3d-4f39-921a-34b68357e668",
   "metadata": {},
   "source": [
    "unconditional fit, allowing signal (alternative hypothesis):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab87f513-4e83-4c39-bc9a-794a9eefa1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize(lambda pars: nll_onoff(non, noff, s=pars[0], b=pars[1], tau=tau), (1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b579fe6a-5bdc-4efb-a7eb-f5e663cb7dcc",
   "metadata": {},
   "source": [
    "makes sense - 6, 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5002b27-459b-4a42-aadf-540532d7bb57",
   "metadata": {},
   "source": [
    "conditional fit, assuming 0 signal (null hypothesis):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68421e5-0f50-4ad2-a127-ada8aa0c99e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize(lambda pars: nll_onoff(non, noff, s=0, b=pars[0], tau=tau), (1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdecc42-6ab0-426a-9457-688e2365340c",
   "metadata": {},
   "source": [
    "background gets slightly \"pulled\", but disagreement with observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae884bfb-ef2c-4814-ab2c-01a8ab88352a",
   "metadata": {},
   "source": [
    "This setup has the nice property that we don't need to do a fit since we can find the maximum likelihood estimates (MLEs) analytically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866d65e4-3b17-47a8-ac5b-43cf221dc3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy\n",
    "from sympy.solvers import solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b13484d-898b-46c1-bce3-31d2fe463093",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_, noff_, s_, b_, tau_ = sympy.symbols(\"n_on n_off s b tau\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137847ae-51f1-4a3d-a8bb-1bac2352518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nll = (s_ + b_) + (tau_ * b_) - (non_ * sympy.log(s_ + b_) + noff_ * sympy.log(tau_ * b_))\n",
    "nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a5e053-78d8-4174-aa6b-bf903d005af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_hat = solve(sympy.diff(nll, s_), s_)[0]\n",
    "s_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60d09ed-da22-4fb9-93b6-40d3f67eb3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_hat = solve(sympy.diff(nll.subs(s_, s_hat), b_), b_)[0]\n",
    "b_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece6bca8-7d55-4857-bf8d-a4a24f3db204",
   "metadata": {},
   "source": [
    "These two are intuitively very clear - without constraint the best-fit signal yield will just be the total number of \"on\" events minus the number of expected background and the background will be exclusively determined from the \"off\" region.\n",
    "\n",
    "The best-fit background for a fixed signal is less clear and we will get 2 solutions for the quadratic equation that results from setting the derivative to 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769acf7f-f044-4e59-96f7-966054bb5927",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_hathat = solve(sympy.diff(nll, b_), b_)\n",
    "display(b_hathat[0])\n",
    "display(b_hathat[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d76207-145c-4ed8-8ade-cb8c77c7d841",
   "metadata": {},
   "source": [
    "Here we only need the case for `s=0`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0685affa-a20c-4553-b03e-28c4fe48f565",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(b_hathat[0].subs(s_, 0))\n",
    "display(b_hathat[1].subs(s_, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c2db36-22e8-4ebe-8981-db1ffa4d8465",
   "metadata": {},
   "source": [
    "We can simplify the expression under the square root and see that the first solution is 0 which is not a useful estimate, so we only need the second solution.\n",
    "\n",
    "The relevant MLEs to get the log-likelihood ratio test statistic are therefore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee040dd-9c64-417c-a325-66f56a2a2169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mles(non, noff, b, tau):\n",
    "    \"Maximum likelihood estimates for the on-off likelihood\"\n",
    "    shat = non - b\n",
    "    bhat = noff / tau\n",
    "    bhathat = (noff + non) / (tau + 1)\n",
    "    return shat, bhat, bhathat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd97e5d-675d-491e-ad8e-e71a992c130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mles(non, noff, b, tau) # consistent with fit above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3c5901-2183-4d19-9607-5a169fe9186f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nllr(non, noff, tau):\n",
    "    \"\"\"\n",
    "    Negative log likelihood ratio for on-off problem\n",
    "    \"\"\"\n",
    "    b = noff / tau\n",
    "    shat, bhat, bhathat = mles(non, noff, b, tau)\n",
    "\n",
    "    cond_nll = nll_onoff(non, noff, s=0, b=bhathat, tau=tau)\n",
    "    uncond_nll = nll_onoff(non, noff, s=shat, b=bhat, tau=tau)\n",
    "\n",
    "    return np.where(\n",
    "        (shat <= 0) | (bhat <= 0),\n",
    "        0, # we choose to view lower counts as background expectation not as evidence against signal\n",
    "        cond_nll - uncond_nll\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a69b1c5-bb6d-4f1f-a516-9a64d25aff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nllr_obs = nllr(non, noff, tau)\n",
    "nllr_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2524ecc-8b93-4d33-988a-8d0d2465036a",
   "metadata": {},
   "source": [
    "Is this significant? Let's throw toys under null hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f64d42-5362-46ad-bc52-1856c79304df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toy_nllr():\n",
    "    non = np.random.poisson(b)\n",
    "    noff = np.random.poisson(tau * b)\n",
    "    return nllr(non, noff, tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefe4d4f-d6ad-45ba-b6a1-dd9d702e3761",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.poisson(b, size=n_toys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4d4b1c-ce3d-42ca-8b51-fb25df73c3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_toys = 100000\n",
    "toys = nllr(np.random.poisson(b, size=n_toys), np.random.poisson(tau * b, size=n_toys), tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3ad14d-baba-4529-be53-1964f548a593",
   "metadata": {},
   "outputs": [],
   "source": [
    "toys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c01474-71c0-445c-bd2f-d0ca419124e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(toys, bins=100);\n",
    "plt.axvline(nllr_obs, color=\"red\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c945bc-2ab8-4928-8c23-5516770e9e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue = (toys >= nllr_obs).mean()\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f439828-4c77-407b-9f75-590b82f427bf",
   "metadata": {},
   "source": [
    "Exercise: overlay chi2 distribution, calculate pvalue from asymptotic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ac233f-f21c-45bf-a5a3-f3ea3158ca52",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(nllr_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fa952e-ac16-4a8f-9acd-fff4d1f12617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pvalue_to_significance(pvalue):\n",
    "    return stats.norm.isf(pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241b4b57-5d82-40af-9b5d-3244ca0c56db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def significance_to_pvalue(significance):\n",
    "    return stats.norm.sf(significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f109f8c-415e-4134-85c3-df1e3e3d6e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_to_pvalue(np.sqrt(2 * nllr_obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c7c3cb-033d-4f32-8dc4-57ac660ca6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.5*(1 - stats.chi2.cdf(2*nllr_obs, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b49b8d7-3571-4408-b0f3-2135e42e796c",
   "metadata": {},
   "source": [
    "The 0.5 comes intuitively from the fact that around in half of the cases we would have gotten negative signal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
